# -- CloudZero host to send metrics to.
host: api.cloudzero.com
# -- Account ID of the account the cluster is running in. This must be a string - even if it is a number in your system.
cloudAccountId: null
# -- Name of the clusters.
clusterName: null
# -- Region the cluster is running in.
region: null

# -- CloudZero API key. Required if existingSecretName is null.
apiKey: null
# -- If set, the agent will use the API key in this Secret to authenticate with CloudZero.
existingSecretName: null

# -- The following lists of metrics are required for CloudZero to function.
# -- Modifications made to these lists may cause issues with the processing of cluster data
kubeMetrics:
  - kube_node_info
  - kube_node_status_capacity
  - kube_pod_container_resource_limits
  - kube_pod_container_resource_requests
  - kube_pod_labels
  - kube_pod_info
containerMetrics:
  - container_cpu_usage_seconds_total
  - container_memory_working_set_bytes
  - container_network_receive_bytes_total
  - container_network_transmit_bytes_total
insightsMetrics:
  - go_memstats_alloc_bytes
  - go_memstats_heap_alloc_bytes
  - go_memstats_heap_idle_bytes
  - go_memstats_heap_inuse_bytes
  - go_memstats_heap_objects
  - go_memstats_last_gc_time_seconds
  - go_memstats_alloc_bytes
  - go_memstats_stack_inuse_bytes
  - go_goroutines
  - process_cpu_seconds_total
  - process_max_fds
  - process_open_fds
  - process_resident_memory_bytes
  - process_start_time_seconds
  - process_virtual_memory_bytes
  - process_virtual_memory_max_bytes
  - remote_write_timeseries_total
  - remote_write_response_codes_total
  - remote_write_payload_size_bytes
  - remote_write_failures_total
  - remote_write_records_processed_total
  - remote_write_db_failures_total
  - http_requests_total
  - storage_write_failure_total
prometheusMetrics:
  - go_memstats_alloc_bytes
  - go_memstats_heap_alloc_bytes
  - go_memstats_heap_idle_bytes
  - go_memstats_heap_inuse_bytes
  - go_memstats_heap_objects
  - go_memstats_last_gc_time_seconds
  - go_memstats_alloc_bytes
  - go_memstats_stack_inuse_bytes
  - go_goroutines
  - process_cpu_seconds_total
  - process_max_fds
  - process_open_fds
  - process_resident_memory_bytes
  - process_start_time_seconds
  - process_virtual_memory_bytes
  - process_virtual_memory_max_bytes
  - prometheus_agent_corruptions_total
  - prometheus_api_remote_read_queries
  - prometheus_http_requests_total
  - prometheus_notifications_alertmanagers_discovered
  - prometheus_notifications_dropped_total
  - prometheus_remote_storage_bytes_total
  - prometheus_remote_storage_histograms_failed_total
  - prometheus_remote_storage_histograms_total
  - prometheus_remote_storage_metadata_bytes_total
  - prometheus_remote_storage_metadata_failed_total
  - prometheus_remote_storage_metadata_retried_total
  - prometheus_remote_storage_metadata_total
  - prometheus_remote_storage_samples_dropped_total
  - prometheus_remote_storage_samples_failed_total
  - prometheus_remote_storage_samples_in_total
  - prometheus_remote_storage_samples_total
  - prometheus_remote_storage_shard_capacity
  - prometheus_remote_storage_shards
  - prometheus_remote_storage_shards_desired
  - prometheus_remote_storage_shards_max
  - prometheus_remote_storage_shards_min
  - prometheus_sd_azure_cache_hit_total
  - prometheus_sd_azure_failures_total
  - prometheus_sd_discovered_targets
  - prometheus_sd_dns_lookup_failures_total
  - prometheus_sd_failed_configs
  - prometheus_sd_file_read_errors_total
  - prometheus_sd_file_scan_duration_seconds
  - prometheus_sd_file_watcher_errors_total
  - prometheus_sd_http_failures_total
  - prometheus_sd_kubernetes_events_total
  - prometheus_sd_kubernetes_http_request_duration_seconds
  - prometheus_sd_kubernetes_http_request_total
  - prometheus_sd_kubernetes_workqueue_depth
  - prometheus_sd_kubernetes_workqueue_items_total
  - prometheus_sd_kubernetes_workqueue_latency_seconds
  - prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds
  - prometheus_sd_kubernetes_workqueue_unfinished_work_seconds
  - prometheus_sd_kubernetes_workqueue_work_duration_seconds
  - prometheus_sd_received_updates_total
  - prometheus_sd_updates_delayed_total
  - prometheus_sd_updates_total
  - prometheus_target_scrape_pool_reloads_failed_total
  - prometheus_target_scrape_pool_reloads_total
  - prometheus_target_scrape_pool_sync_total
  - prometheus_target_scrape_pools_failed_total
  - prometheus_target_scrape_pools_total
  - prometheus_target_sync_failed_total
  - prometheus_target_sync_length_seconds
# -- Any items added to this array will be added to the metrics that are sent to CloudZero, in addition to the minimal labels that CloudZero requires.
additionalMetricLabels: []

# Agent largely contains top-level settings which are often shared by multiple
# components within this chart, or used as defaults in case values are not
# explicitly set per-component.
agent:
  # The container image used for most CloudZero components.
  image:
    repository: ghcr.io/cloudzero/cloudzero-agent/cloudzero-agent
    tag: 1.1.0-beta-3  # <- Software release corresponding to this chart version.
    digest:
    pullPolicy: IfNotPresent

# metricFilters is used to determine which metrics are sent to CloudZero, as
# well as whether they are considered to be cost metrics or observability
# metrics.
#
# There are two sets of filters for each type (cost/observability): name and
# labels. The name filters are applied to the name to determine whether the
# metric should be included in the relevant output. If it is to be included, the
# relevant labels filters are applied to each label to determine whether the
# label should be included.
#
# In the event that there are no filters, the subject is always assumed to
# match.
#
# Note that for each match type (exact, prefix, suffix, contains, regex) there
# is an "additional..." property. This is to allow you to supply supplemental
# filters without clobbering the defaults. In general, the "additional..."
# properties should be used in your overrides file, and the unprefixed versions
# should be left alone.
metricFilters:
  cost:
    name:
      exact:
        - container_cpu_usage_seconds_total
        - container_memory_working_set_bytes
        - container_network_receive_bytes_total
        - container_network_transmit_bytes_total
        - kube_node_info
        - kube_node_status_capacity
        - kube_pod_container_resource_limits
        - kube_pod_container_resource_requests
        - kube_pod_labels
        - kube_pod_info
      prefix:
        - "cloudzero_"
      suffix: []
      contains: []
      regex: []

      additionalExact: []
      additionalPrefix: []
      additionalSuffix: []
      additionalContains: []
      additionalRegex: []
    labels:
      exact:
        - board_asset_tag
        - container
        - created_by_kind
        - created_by_name
        - image
        - instance
        - name
        - namespace
        - node
        - node_kubernetes_io_instance_type
        - pod
        - product_name
        - provider_id
        - resource
        - unit
        - uid
      prefix:
        - "_"
        - "label_"
        - "app.kubernetes.io/"
        - "k8s."
      suffix: []
      contains: []
      regex: []
      additionalExact: []
      additionalPrefix: []
      additionalSuffix: []
      additionalContains: []
      additionalRegex: []

  observability:
    name:
      exact:
        - go_gc_duration_seconds
        - go_gc_duration_seconds_count
        - go_gc_duration_seconds_sum
        - go_gc_gogc_percent
        - go_gc_gomemlimit_bytes
        - go_goroutines
        - go_memstats_alloc_bytes
        - go_memstats_heap_alloc_bytes
        - go_memstats_heap_idle_bytes
        - go_memstats_heap_inuse_bytes
        - go_memstats_heap_objects
        - go_memstats_last_gc_time_seconds
        - go_memstats_stack_inuse_bytes
        - go_threads
        - http_request_duration_seconds_bucket
        - http_request_duration_seconds_count
        - http_request_duration_seconds_sum
        - http_requests_total
        - process_cpu_seconds_total
        - process_max_fds
        - process_open_fds
        - process_resident_memory_bytes
        - process_start_time_seconds
        - process_virtual_memory_bytes
        - process_virtual_memory_max_bytes
        - prometheus_agent_corruptions_total
        - prometheus_api_remote_read_queries
        - prometheus_http_requests_total
        - prometheus_notifications_alertmanagers_discovered
        - prometheus_notifications_dropped_total
        - prometheus_remote_storage_bytes_total
        - prometheus_remote_storage_exemplars_in_total
        - prometheus_remote_storage_histograms_failed_total
        - prometheus_remote_storage_histograms_in_total
        - prometheus_remote_storage_histograms_total
        - prometheus_remote_storage_metadata_bytes_total
        - prometheus_remote_storage_metadata_failed_total
        - prometheus_remote_storage_metadata_retried_total
        - prometheus_remote_storage_metadata_total
        - prometheus_remote_storage_samples_dropped_total
        - prometheus_remote_storage_samples_failed_total
        - prometheus_remote_storage_samples_in_total
        - prometheus_remote_storage_samples_total
        - prometheus_remote_storage_shard_capacity
        - prometheus_remote_storage_shards
        - prometheus_remote_storage_shards_desired
        - prometheus_remote_storage_shards_max
        - prometheus_remote_storage_shards_min
        - prometheus_remote_storage_string_interner_zero_reference_releases_total
        - prometheus_sd_azure_cache_hit_total
        - prometheus_sd_azure_failures_total
        - prometheus_sd_discovered_targets
        - prometheus_sd_dns_lookup_failures_total
        - prometheus_sd_failed_configs
        - prometheus_sd_file_read_errors_total
        - prometheus_sd_file_scan_duration_seconds
        - prometheus_sd_file_watcher_errors_total
        - prometheus_sd_http_failures_total
        - prometheus_sd_kubernetes_events_total
        - prometheus_sd_kubernetes_http_request_duration_seconds
        - prometheus_sd_kubernetes_http_request_total
        - prometheus_sd_kubernetes_workqueue_depth
        - prometheus_sd_kubernetes_workqueue_items_total
        - prometheus_sd_kubernetes_workqueue_latency_seconds
        - prometheus_sd_kubernetes_workqueue_longest_running_processor_seconds
        - prometheus_sd_kubernetes_workqueue_unfinished_work_seconds
        - prometheus_sd_kubernetes_workqueue_work_duration_seconds
        - prometheus_sd_received_updates_total
        - prometheus_sd_updates_delayed_total
        - prometheus_sd_updates_total
        - prometheus_target_scrape_pool_reloads_failed_total
        - prometheus_target_scrape_pool_reloads_total
        - prometheus_target_scrape_pool_sync_total
        - prometheus_target_scrape_pools_failed_total
        - prometheus_target_scrape_pools_total
        - prometheus_target_sync_failed_total
        - prometheus_target_sync_length_seconds
        - promhttp_metric_handler_requests_in_flight
        - promhttp_metric_handler_requests_total
        - remote_write_db_failures_total
        - remote_write_failures_total
        - remote_write_payload_size_bytes
        - remote_write_records_processed_total
        - remote_write_response_codes_total
        - remote_write_timeseries_total
        - storage_write_failure_total
        # shipper
        - function_execution_seconds
        - shipper_shutdown_total
        - shipper_new_files_error_total
        - shipper_new_files_processing_current
        - shipper_handle_request_file_count
        - shipper_handle_request_success_total
        - shipper_presigned_url_error_total
        - shipper_replay_request_total
        - shipper_replay_request_current
        - shipper_replay_request_file_count
        - shipper_replay_request_error_total
        - shipper_replay_request_abandon_files_total
        - shipper_replay_request_abandon_files_error_total
        - shipper_disk_total_size_bytes
        - shipper_current_disk_usage_bytes
        - shipper_current_disk_usage_percentage
        - shipper_current_disk_unsent_file
        - shipper_current_disk_sent_file
        - shipper_disk_replay_request_current
        - shipper_disk_cleanup_failure_total
        - shipper_disk_cleanup_success_total
        - shipper_disk_cleanup_percentage
      prefix:
        - czo_
      suffix: []
      contains: []
      regex: []
      additionalExact: []
      additionalPrefix: []
      additionalSuffix: []
      additionalContains: []
      additionalRegex: []
    labels:
      exact: []
      prefix: []
      suffix: []
      contains: []
      regex: []
      additionalExact: []
      additionalPrefix: []
      additionalSuffix: []
      additionalContains: []
      additionalRegex: []

prometheusConfig:
  configMapNameOverride: ""
  configMapAnnotations: {}
  configOverride: ""
  globalScrapeInterval: 60s
  scrapeJobs:
    # -- Enables the kube-state-metrics scrape job.
    kubeStateMetrics:
      enabled: true
      # Scrape interval for kubeStateMetrics job
      scrapeInterval: 60s
    # -- Enables the cadvisor scrape job.
    cadvisor:
      enabled: true
      # Scrape interval for nodesCadvisor job
      scrapeInterval: 60s
    # -- Enables the prometheus scrape job.
    prometheus:
      enabled: true
      # Scrape interval for prometheus job
      scrapeInterval: 120s
    aggregator:
      enabled: true
      # Scrape interval for aggregator job
      scrapeInterval: 120s
    # -- Any items added to this list will be added to the Prometheus scrape configuration.
    additionalScrapeJobs: []

# General server settings that apply to both the prometheus agent server and the webhook server
serverConfig:
  # -- The agent will use this file path on the container filesystem to get the CZ API key.
  containerSecretFilePath: /etc/config/secrets/
  # -- The agent will look for a file with this name to get the CZ API key.
  containerSecretFileName: value

# -- The following settings are for the init-backfill-job, which is used to backfill data from the cluster to CloudZero.
initBackfillJob:
  # -- By default, all image settings use those set in insightsController.server. Optionally use the below to override. This should not be common.
  # imagePullSecrets: []
  image:
    repository:
    tag:
    digest:
    pullPolicy:
  enabled: true

# -- This is a deprecated field that is replaced by initBackfillJob. However, the fields are identical, and initScrapeJob can still be used to configure the backFill/scrape Job.
# initScrapeJob:
# -- By default, all image settings use those set in insightsController.server. Optionally use the below to override. This should not be common.
# imagePullSecrets: []
# image:
#   repository:
#   tag:
#   pullPolicy:

initCertJob:
  enabled: true
  # -- Defaults to the same setting as the insightsController.server if set, otherwise left empty.
  # imagePullSecrets: []
  image:
    repository: bitnami/kubectl
    pullPolicy:
    digest:
    tag: "1.32.0"
  dnsPolicy: ClusterFirst
  dnsConfig: {}
  rbac:
    create: true
    serviceAccountName: ""
    clusterRoleName: ""
    clusterRoleBindingName: ""

kubeStateMetrics:
  enabled: true
  image:
    registry: registry.k8s.io
    repository: kube-state-metrics/kube-state-metrics
    tag: "v2.10.1"
    digest:
  nameOverride: "cloudzero-state-metrics"
  # Disable CloudZero KSM as a Scrape Target since the service endpoint is explicitly defined
  # by the Validators config file.
  prometheusScrape: false
  # Set a default port other than 8080 to avoid collisions with any existing KSM services.
  service:
    port: 8080

  # -- Overriding static scrape target address for an existing KSM.
  # -- Set to service <service-name>.<namespace>.svc.cluster.local:port if built-in is disabled (enable=false above)
  # targetOverride: kube-state-metrics.monitors.svc.cluster.local:8080
  # -- If targetOverride is set and kubeStateMetrics.enabled is true, it is likely that fullnameOverride below must be set as well.
  # -- This should not be a common configuration
  # fullnameOverride: "kube-state-metrics"

# -- Annotations to be added to the Secret, if the chart is configured to create one
secretAnnotations: {}
imagePullSecrets: []

scheme: https
endpoint: /v1/container-metrics

# environment validator image allows for CI to use a different image in testing
validator:
  serviceEndpoints:
    kubeStateMetrics:
  # -- Flag to skip validator failure if unable to connect to the CloudZero API.
  name: env-validator
  image:
    repository:
    tag:
    digest:
    pullPolicy:

server:
  name: server
  image:
    repository: quay.io/prometheus/prometheus
    # if not set appVersion field from Chart.yaml is used
    tag:
    # When digest is set to a non-empty value, images will be pulled by digest (regardless of tag value).
    digest:
    pullPolicy:
  nodeSelector: {}
  resources:
    requests:
      memory: 512Mi
      cpu: 250m
    limits:
      memory: 1024Mi
  deploymentAnnotations: {}
  podAnnotations: {}
  dnsPolicy: ClusterFirst
  dnsConfig: {}
  agentMode: true
  args:
    - --config.file=/etc/config/prometheus/configmaps/prometheus.yml
    - --web.enable-lifecycle
    - --web.console.libraries=/etc/prometheus/console_libraries
    - --web.console.templates=/etc/prometheus/consoles
  persistentVolume:
    existingClaim: ""
    enabled: false
    mountPath: /data
    subPath: ""
    storageClass: ""
    size: 8Gi
    accessModes:
      - ReadWriteOnce
  # --Limit the size to 8Gi to lower impact on the cluster, and to provide a reasonable backup for the WAL
  emptyDir:
    sizeLimit: 8Gi

insightsController:
  enabled: true
  labels:
    enabled: true
    patterns:
      - "app.kubernetes.io/component"
      # - '.*'
    resources:
      pods: true
      namespaces: true
      deployments: false
      statefulsets: false
      nodes: false
      jobs: false
      cronjobs: false
      daemonsets: false
  annotations:
    enabled: false
    patterns:
      - ".*"
    resources:
      pods: true
      namespaces: true
      deployments: false
      statefulsets: false
      nodes: false
      jobs: false
      cronjobs: false
      daemonsets: false
  tls:
    # -- If disabled, the insights controller will not mount a TLS certificate from a Secret, and the user is responsible for configuring a method of providing TLS information to the webhook-server container.
    enabled: true
    # -- If left as an empty string, the certificate will be generated by the chart. Otherwise, the provided value will be used.
    crt: ""
    # -- If left as an empty string, the certificate private key will be generated by the chart. Otherwise, the provided value will be used.
    key: ""
    secret:
      # -- If set to true, a Secret will be created to store the TLS certificate and key.
      create: true
      # -- If set, the Secret will be created with this name. Otherwise, a default name will be generated.
      name: ""
    # -- The following TLS certificate information is for a self signed certificate. It is used as a default value for the validating admission webhook and the webhook server.
    # -- This path determines the location within the container where the TLS certificate and key will be mounted.
    mountPath: /etc/certs
    # -- This is the caBundle used by the Validating Admission Webhook when sending requests to the webhook server. If left empty, the default self-signed certificate will be used.
    # Set this value to an empty string if using cert-manager to manage the certificate instead. Otherwise, set this to the base64 encoded caBundle of the desired certificate.
    caBundle: ""
    # -- If enabled, the certificate will be managed by cert-manager, which must already be present in the cluster.
    # If disabled, a default self-signed certificate will be used.
    useCertManager: false
  server:
    name: webhook-server
    replicaCount: 3
    # -- Uncomment to use a specific imagePullSecrets; otherwise, the default top level imagePullSecrets is used.
    # imagePullSecrets: []
    image:
      repository:
      tag:
      pullPolicy:
    port: 8443
    read_timeout: 10s
    write_timeout: 10s
    send_timeout: 1m
    send_interval: 1m
    idle_timeout: 120s
    logging:
      level: info
    healthCheck:
      enabled: true
      path: /healthz
      port: 8443
      initialDelaySeconds: 15
      periodSeconds: 20
      timeoutSeconds: 3
      successThreshold: 1
      failureThreshold: 5
    nodeSelector: {}
    tolerations: []
    affinity: {}
    dnsPolicy: ClusterFirst
    dnsConfig: {}
  volumeMounts: []
  volumes: []
  resources: {}
  podAnnotations: {}
  podLabels: {}
  service:
    port: 443
  webhooks:
    annotations: {}
    namespaceSelector: {}
    configurations:
      pods:
        path: /validate/pod
        apiGroups: ['""']
      namespaces:
        path: /validate/namespace
        apiGroups: ['""']
      deployments:
        path: /validate/deployment
        apiGroups: ["apps"]
      statefulsets:
        path: /validate/statefulset
        apiGroups: ["apps"]
      nodes:
        path: /validate/node
        apiGroups: ['""']
      jobs:
        path: /validate/job
        apiGroups: ["batch"]
      cronjobs:
        path: /validate/cronjob
        apiGroups: ["batch"]
      daemonsets:
        path: /validate/daemonset
        apiGroups: ["apps"]

serviceAccount:
  create: true
  name: ""
  annotations: {}

rbac:
  create: true

commonMetaLabels: {}

configmapReload:
  reloadUrl: ""
  env: []
  prometheus:
    enabled: true
    image:
      repository: quay.io/prometheus-operator/prometheus-config-reloader
      tag: v0.70.0
      digest: ""
      pullPolicy: IfNotPresent

    containerSecurityContext: {}
    resources: {}

# The aggregator provides an intermediary between the CloudZero Agent and the CloudZero API.
# It is composed of two applications, the collector and the shipper.

# The collector application provides an endpoint for the CloudZero Agent to write metrics to.
# It filters out any unwanted metrics as it receives them, aggregates the wanted metrics,
# and stores them in a compressed format on disk until they are ready to be uploaded to the
# CloudZero servers. Once the collector has aggregated sufficient metrics (or a given amount of time has elapsed)
# the data is sent to the shipper.

# The shipper will process the completed metrics files and push them to the remote server.
# It will also handle any requests from the server to re-send any missing or incomplete data,
# ensuring that there is no data loss in the event of any loss of communication with the CloudZero API,
# even when a misconfiguration (such as an incorrect API key) prevents it.
aggregator:
  enabled: false
  replicas: 1
  logging:
    # Logging level that will be posted to stdout.
    # Valid values are: 'debug', 'info', 'warn', 'error'
    level: info
  # Top-level directory containing CloudZero data. There will be subdirectories for configuration (the mounted ConfigMap)
  # and the API key (typically a mounted Secret), and data to be uploaded to CloudZero, specifically metrics.
  # This value is really only visible internally in the container, so you shouldn't generally need to change it.
  # Set `aggregator.database.purgeRules` to control the cleanup behavior of this directory
  mountRoot: /cloudzero
  # Whether to enable the profiling endpoint (/debug/pprof/). This should
  # generally be disabled in production.
  profiling: false
  image:
    repository:
    tag:
    digest:
    pullPolicy:
  dnsPolicy: ClusterFirst
  dnsConfig: {}
  cloudzero:
    # Interval between attempts to ship metrics to the remote endpoint.
    sendInterval: 1m
    # Max time the aggregator will spend attempting to ship metrics to the remote endpoint.
    sendTimeout: 30s
    rotateInterval: 30m
  database:
    # Max number of records per file. Use this to adjust file sizes uploaded to the server. The default value is good in most cases.
    maxRecords: 1500000
    # Max interval to flush a metrics file. This is mostly useful for smaller clusters with little activity.
    maxInterval: 10m
    # Compression level to use when compressing metrics files on-disk.
    # Valid value range from 0-11, with higher values yielding improved compression ratios
    # at the expense of speed and memory usage.
    # Read more about brotli compression here: https://github.com/google/brotli/blob/master/c/tools/brotli.md#options
    compressionLevel: 8
    # The rules that the application will follow in respect to cleaning up old files that have been uploaded to the
    # Cloudzero platform.
    # Generally, the defaults will be okay for the majority of use cases. But, the options are here for more advanced
    # users to optimize disk usage. For example, the default case is to keep uploaded files around for 90 days, as this
    # falls in line with most customer's data tolerance policies. But, if deployed on a more active and/or larger cluster,
    # this value can be lowered to keep disk usage lower with the tradeoff of less data-retention. Regardless of what you
    # define here if there is disk pressure detected, files will be deleted (oldest first) to free space.
    purgeRules:
      # How long to keep uploaded files. This option can be useful to optimize the storage required by the collector/shipper
      # architecture on your nodes.
      # `2160h` is 90 days, and is a reasonable default. This can reasonably be any value, as the application will force
      # remove files if space is constrained.
      # `0s` is also a valid option and can signify that you do not want to keep uploaded files at all. Though do note
      # that this could possibly result in data loss if there are transient upload failures during the lifecycle of the application.
      metricsOlderThan: 2160h
      # If set to true (default), then files older than `metricsOlderThan` will not be deleted unless there is detected storage pressure.
      # For example, if there are files older than `metricsOlderThan` but only 30% of storage space is used, the files will not be deleted.
      lazy: true
      # This controls the percentage of files the application will remove when there is critical storage pressure.
      # This is defined by >95% of storage usage.
      percent: 20
  collector:
    port: 8080
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
  shipper:
    resources:
      requests:
        memory: "64Mi"
        cpu: "100m"
      limits:
        memory: "1024Mi"
        cpu: "2000m"
